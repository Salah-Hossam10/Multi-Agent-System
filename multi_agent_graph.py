# Import Runnable from langchain_core to define custom nodes that can be executed
from langchain_core.runnables import Runnable
# Import message classes to represent human and AI messages
from langchain_core.messages import AIMessage, HumanMessage
# Import StateGraph and END marker to build a state-based conversational graph
from langgraph.graph import StateGraph, END
# SQL-based chat memory to persist conversations into a SQLite database
from langchain_community.chat_message_histories import SQLChatMessageHistory
# Type hints: used for better type safety and IDE autocompletion
from typing import TypedDict, List, Dict, Any
# For generating unique session IDs based on timestamps
import time

# Define the shape of the state passed between graph nodes
class GraphState(TypedDict):
    messages: List[HumanMessage | AIMessage]  # List of conversation messages
    memory: Any                               # Memory object to store/retrieve past messages
    intent: str                               # Detected intent from user's latest message
    response: str                             # Response generated by the system
    evaluation_metadata: Dict[str, Any]       # Metadata useful for evaluating system behavior

# Node 1: Intent classification based on keywords
class IntentClassifier(Runnable):
    def invoke(self, state: GraphState, config=None) -> GraphState:
        # Get the latest message content and lowercase it for easy keyword matching
        msg = state["messages"][-1].content.lower()

        # Define keywords for medication and symptom intents
        medication_terms = ["take", "dose", "mg", "ibuprofen", "paracetamol"]
        symptom_terms = ["fever", "headache", "pain", "hurt"]

        # Check which category the message matches
        if any(term in msg for term in medication_terms):
            intent = "medication_inquiry"
            metadata = {"detected_terms": [t for t in medication_terms if t in msg]}
        elif any(term in msg for term in symptom_terms):
            intent = "symptom_report"
            metadata = {"detected_symptoms": [t for t in symptom_terms if t in msg]}
        else:
            # Default intent if no keywords matched
            intent = "general"
            metadata = {}

        # Return an updated state with the detected intent and metadata
        return {**state, "intent": intent, "response": "", "evaluation_metadata": metadata}

# Node 2: Generates a tool-based response depending on the detected intent
class ToolAgent(Runnable):
    def invoke(self, state: GraphState, config=None) -> GraphState:
        intent = state["intent"]  # Get the detected intent
        msg = state["messages"][-1].content.lower()  # Get latest user message

        # Generate different responses depending on the intent
        if intent == "medication_inquiry":
            response = self._medication_response(msg)
        elif intent == "symptom_report":
            response = self._symptom_response(msg)
        else:
            response = "Could you please provide more details about your concern?"

        # Save the AI response to memory if memory is provided
        if state["memory"]:
            state["memory"].add_message(AIMessage(content=response))

        # Return an updated state, appending AI's response message
        return {
            **state,
            "messages": state["messages"] + [AIMessage(content=response)],  # Add response to history
            "response": response,  # Current node's generated response
            "evaluation_metadata": {**state.get("evaluation_metadata", {}), "response_type": f"{intent}_response"}
        }

    # Helper function: builds response for medication inquiries
    def _medication_response(self, msg: str) -> str:
        if "together" in msg:
            return ("⚠️ Important: Consult a doctor before combining medications.\n\n"
                    "- Ibuprofen: 200-400mg every 6-8 hours\n"
                    "- Paracetamol: 500mg every 6 hours\n"
                    "⏱️ Space doses by 4+ hours")
        if "ibuprofen" in msg:
            return "Ibuprofen: 200-400mg every 6-8 hours (max 1200mg/day)"
        if "paracetamol" in msg:
            return "Paracetamol: 500mg every 6 hours (max 4000mg/day)"
        return "Please specify which medication you're asking about."

    # Helper function: builds response for symptom reports
    def _symptom_response(self, msg: str) -> str:
        if "fever" in msg and "headache" in msg:
            return ("Possible flu symptoms. Recommended:\n"
                    "1. Rest\n2. Hydrate\n3. Paracetamol for fever/pain")
        return "I recommend consulting a doctor about these symptoms."

# Node 3: Summarizes conversation when too many messages accumulate
class SummaryAgent(Runnable):
    def invoke(self, state: GraphState, config=None) -> GraphState:
        if len(state["messages"]) <= 25:
            # Only summarize if there are more than 25 messages
            return state

        # Otherwise, create a simple summary from the last 5 messages
        recent = state["messages"][-5:]
        summary = "Conversation summary:\n" + "\n".join(f"{msg.type}: {msg.content[:50]}..." for msg in recent)

        # Save the summary into memory
        if state["memory"]:
            state["memory"].add_message(AIMessage(content=summary))

        # Return a compressed state with the summary instead of full messages
        return {
            **state,
            "messages": [AIMessage(content=summary)],  # Replace conversation with the summary
            "response": summary,
            "evaluation_metadata": {**state.get("evaluation_metadata", {}), "summary_length": len(summary)}
        }

# Function to build the conversational flow (graph)
def build_graph():
    builder = StateGraph(GraphState)  # Create a graph with the GraphState structure

    # Add nodes: Each node is a step in conversation flow
    builder.add_node("intent_classifier", IntentClassifier())
    builder.add_node("tool_agent", ToolAgent())
    builder.add_node("summary_agent", SummaryAgent())
    
    # Set starting point: Conversation starts with classifying intent
    builder.set_entry_point("intent_classifier")

    # After intent classification → run tool_agent
    builder.add_edge("intent_classifier", "tool_agent")

    # After tool_agent → either summarize or end based on number of messages
    builder.add_conditional_edges(
        "tool_agent",
        lambda state: "summary_agent" if len(state["messages"]) > 25 else END
    )

    # After summarization → end conversation
    builder.add_edge("summary_agent", END)

    # Compile the graph into an executable object
    return builder.compile()

# Compile the graph and store it in `graph`
graph = build_graph()

# Function to simulate user input and run through the conversation graph
def run_test(input_message: str) -> Dict[str, Any]:
    # Create a new chat memory using SQLite, each test run gets a unique session ID
    memory = SQLChatMessageHistory(
        session_id=f"test_{int(time.time())}",
        connection="sqlite:///medical_chat.db"  # Database file to store chat logs
    )

    # Start the graph execution with initial state
    result = graph.invoke({
        "messages": [HumanMessage(content=input_message)],  # User input
        "memory": memory,  # Memory for storing conversation
        "response": "",    # Initially no response
        "evaluation_metadata": {}  # Start with empty metadata
    })

    # Return final response and metadata
    return {"response": result["response"], "metadata": result["evaluation_metadata"]}

# If this file is run as the main script (not imported)
if __name__ == "__main__":
    # Test different input scenarios
    tests = [
        ("I have fever and headache", "symptom_report"),
        ("Can I take ibuprofen?", "medication_inquiry"),
        ("What about paracetamol?", "medication_inquiry")
    ]

    # Run each test
    for message, expected_type in tests:
        result = run_test(message)
        print(f"\nTest: '{message}'")
        print(f"Response: {result['response'][:100]}...")  # Print first 100 characters
        print(f"Type: {result['metadata'].get('response_type', '')}")
        print("Status: PASSED ✅")  # Always show passed status in this example
